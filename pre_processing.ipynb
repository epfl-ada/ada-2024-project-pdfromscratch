{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "This notebook contains pre-processing steps to create cleaned data in `/data` from the raw datasets downloaded and stored in `/raw_data`. Before running this notebook, please ensure that you ran `src/scripts/download.py` to download the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "from thefuzz import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('data/beer_advocate', exist_ok=True)\n",
    "os.makedirs('data/matched_beer_data', exist_ok=True)\n",
    "os.makedirs('data/rate_beer', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map region to country (useful when we only have the region)\n",
    "with open('src/utils/region_to_country.json', 'r') as region_to_country_file:\n",
    "    REGION_TO_COUNTRY = json.load(region_to_country_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign unique code to each country\n",
    "df_iso_codes = pd.read_csv('src/utils/iso_codes.csv')[['name', 'alpha-3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get the country code from the country using fuzzy matching\n",
    "def get_closest_match_or_none(query: str, serie_choices: pd.Series, serie_values: pd.Series, threshold: int = 80):\n",
    "    match, score, _ = process.extractOne(query, serie_choices)\n",
    "    if score >= threshold:\n",
    "        return serie_values[serie_choices == match].values[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_location(serie_locations: pd.Series):\n",
    "    serie_locations.replace({\n",
    "        'UNKNOWN': pd.NA,\n",
    "        'Swaziland': 'Esawtini',                                                # Swaziland changed its name to Esawtini\n",
    "        'Northern Ireland': 'United Kingdom, Northern Ireland',                 # Northern Ireland is part of the United Kingdom\n",
    "        'Aotearoa': 'New Zealand',                                              # Aotearoa is the Maori name for New Zealand\n",
    "        'Nagorno-Karabakh': 'Azerbaijan',                                       # Nagorno-Karabakh is a disputed territory (currenlty controlled by Azerbaijan)\n",
    "        'Transdniestra': 'Moldova',                                             # Transdniestra is a disputed territory (currenlty controlled by Moldova)\n",
    "        'Tibet': 'China',                                                       # Tibet is an autonomous region of China\n",
    "        'Abkhazia': 'Georgia',                                                  # Abkhazia is a disputed territory (currenlty controlled by Georgia)\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Match location with Google Maps links and extract the location (before the </a> tag)\n",
    "    extracted_location_matches = serie_locations.str.extract(r'^(.*?)(?=</a>)|^(.*)$')\n",
    "    serie_locations = extracted_location_matches[0].fillna(extracted_location_matches[1])   \n",
    "\n",
    "    splits = serie_locations.str.split(', ', expand=True)\n",
    "    splits.rename(columns={0: 'country', 1: 'region'}, inplace=True)\n",
    "\n",
    "    # Replace occurence of regions that were considered as countries\n",
    "    splits['country'] = splits['country'].replace(REGION_TO_COUNTRY)\n",
    "\n",
    "    # Try to match the country with the ISO code (exact match)\n",
    "    splits = splits.merge(df_iso_codes[['name', 'alpha-3']], left_on='country', right_on='name', how='left')\n",
    "\n",
    "    # Try to match the country with ISO code (fuzzy match)\n",
    "    splits['alpha-3'] = splits.apply(\n",
    "        lambda row: row['alpha-3'] if pd.notna(row['alpha-3']) or pd.isna(row['country']) else \n",
    "        get_closest_match_or_none(\n",
    "            row['country'],\n",
    "            df_iso_codes['name'],\n",
    "            df_iso_codes['alpha-3']\n",
    "        ), axis=1\n",
    "    )\n",
    "\n",
    "    splits.loc[splits['country'] == 'Kosovo', 'alpha-3'] = 'XKX' # Kosovo is not in the ISO list\n",
    "    splits.loc[splits['country'] == 'Vatican City', 'alpha-3'] = 'VAT' # Vatican City is not in the ISO list\n",
    "\n",
    "    return splits['country'], splits['region'], splits['alpha-3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beer Advocate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_beers = pd.read_csv('raw_data/beer_advocate/beers.csv')\n",
    "df_ba_beers_styles = pd.read_csv('src/utils/beers_styles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_beers.rename(columns={\n",
    "    'style': 'beer_style',\n",
    "    'nbr_ratings': 'ratings_count',\n",
    "    'nbr_reviews': 'reviews_count',\n",
    "    'avg': 'ratings_average',\n",
    "    'ba_score': 'ratings_ba_score',\n",
    "    'bros_score': 'ratings_bros_score',\n",
    "    'abv': 'beer_alcohol_by_volume',\n",
    "    'avg_computed': 'ratings_average_computed',\n",
    "    'nbr_matched_valid_ratings': 'matching_ratings_count',\n",
    "    'avg_matched_valid_ratings': 'matching_ratings_average',\n",
    "}, inplace=True)\n",
    "\n",
    "df_ba_beers.drop(columns=['brewery_name'], inplace=True, errors='ignore')\n",
    "\n",
    "df_ba_beers = df_ba_beers[['beer_id', 'brewery_id', 'beer_name', 'beer_style', 'ratings_count', 'reviews_count', 'ratings_average', 'ratings_ba_score', 'ratings_bros_score', 'beer_alcohol_by_volume', 'ratings_average_computed', 'zscore', 'matching_ratings_count', 'matching_ratings_average']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_beers = df_ba_beers.merge(df_ba_beers_styles, on='beer_style', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_beers.to_csv('data/beer_advocate/beers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breweries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_breweries = pd.read_csv('raw_data/beer_advocate/breweries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_breweries.rename(columns={\n",
    "    'id': 'brewery_id',\n",
    "    'location': 'brewery_location',\n",
    "    'name': 'brewery_name',\n",
    "    'nbr_beers': 'brewery_beers_count',\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of two breweries were missing, we found their location using Google\n",
    "df_ba_breweries.loc[df_ba_breweries['brewery_id'] == 18989, 'brewery_location'] = 'United States'\n",
    "df_ba_breweries.loc[df_ba_breweries['brewery_id'] == 11016, 'brewery_location'] = 'Austria'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_breweries['brewery_country'], df_ba_breweries['brewery_region'], df_ba_breweries['brewery_country_code'] = format_location(df_ba_breweries['brewery_location'])\n",
    "df_ba_breweries.drop(columns=['brewery_location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_breweries.to_csv('data/beer_advocate/breweries.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_users = pd.read_csv('raw_data/beer_advocate/users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_users.rename(columns={\n",
    "    'joined': 'user_created_date',\n",
    "    'location': 'user_location',\n",
    "    'nbr_ratings': 'user_ratings_count',\n",
    "    'nbr_reviews': 'user_reviews_count',\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_users['user_country'], df_ba_users['user_region'], df_ba_users['user_country_code'] = format_location(df_ba_users['user_location'])\n",
    "df_ba_users.drop(columns=['user_location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_users.to_csv('data/beer_advocate/users.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings & Reviews\n",
    "\n",
    "On BeerAdvocate, users can either submit a *rating* or a *review*. The dataset contains two separate text files `ratings.txt` and `reviews.txt`. Ratings and reviews are formatted as (key, value) pairs on each line of a plain text file with empty lines to split different ratings/reviews. \n",
    "\n",
    "The program `txt_to_csv.cpp` is a C++ program that transform a plain text file in a `.csv` file, that can be more easily analyzed using Python and Pandas. The following cell will compile the program using a C++ compiler and run it on the `ratings.txt` file. Indeed, after analyzing the overlapping between the two files, we found that `reviews.txt` is a subset of `ratings.txt`. Thus, we will discard `reviews.txt` and only keep `ratings.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run('g++ -std=c++17 -o src/scripts/txt_to_csv src/scripts/txt_to_csv.cpp', shell=True)\n",
    "\n",
    "subprocess.run([\n",
    "    'src/scripts/txt_to_csv', \n",
    "    'raw_data/beer_advocate/ratings.txt', \n",
    "    'raw_data/beer_advocate/ratings.csv'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_ratings = pd.read_csv('raw_data/beer_advocate/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those columns are likely to have already been deleted by the C++ script, hence the errors='ignore' parameter\n",
    "df_ba_ratings.drop(columns=['user_name', 'brewery_name', 'beer_name', 'style', 'abv'], inplace=True, errors='ignore')\n",
    "df_ba_ratings = df_ba_ratings[['user_id', 'beer_id', 'brewery_id', 'date', 'review', 'rating', 'overall', 'aroma', 'appearance', 'palate', 'taste', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_ratings = df_ba_ratings.sort_values(['user_id', 'date'])\n",
    "\n",
    "df_ba_ratings['user_past_ratings_count']   = df_ba_ratings.groupby('user_id').cumcount()\n",
    "df_ba_ratings['user_past_ratings_average'] = df_ba_ratings.groupby('user_id')['rating'].expanding().mean().shift().reset_index(level=0, drop=True)\n",
    "\n",
    "df_ba_ratings.loc[df_ba_ratings['user_past_ratings_count'] == 0, 'user_past_ratings_average'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_ratings = df_ba_ratings.sort_values(['beer_id', 'date'])\n",
    "\n",
    "df_ba_ratings['beer_past_ratings_count']   = df_ba_ratings.groupby('beer_id').cumcount()\n",
    "df_ba_ratings['beer_past_ratings_average'] = df_ba_ratings.groupby('beer_id')['rating'].expanding().mean().reset_index(level=0).groupby('beer_id')['rating'].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_ratings.to_csv('data/beer_advocate/ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_ba_beers\n",
    "del df_ba_breweries\n",
    "del df_ba_users\n",
    "del df_ba_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RateBeer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rb_beers = pd.read_csv('raw_data/rate_beer/beers.csv')\n",
    "\n",
    "df_rb_beers = df_rb_beers.drop(columns=['brewery_name'])\n",
    "\n",
    "df_rb_beers = df_rb_beers.rename(columns={\n",
    "    'style': 'beer_style',\n",
    "    'nbr_ratings': 'ratings_count',\n",
    "    'avg': 'ratings_average',\n",
    "    'overall_score': 'ratings_overall_score',\n",
    "    'abv': 'beer_alcohol_by_volume',\n",
    "    'avg_computed': 'ratings_average_computed',\n",
    "    'nbr_matched_valid_ratings': 'matching_ratings_count',\n",
    "    'avg_matched_valid_ratings': 'matching_ratings_average',\n",
    "})\n",
    "\n",
    "df_rb_beers.to_csv('data/rate_beer/beers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breweries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rb_breweries = pd.read_csv('raw_data/rate_beer/breweries.csv')\n",
    "\n",
    "df_rb_breweries = df_rb_breweries.rename(columns={\n",
    "    'id': 'brewery_id',\n",
    "    'location': 'brewery_location',\n",
    "    'name': 'brewery_name',\n",
    "    'nbr_beers': 'brewery_beers_count',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rb_breweries['brewery_country'], df_rb_breweries['brewery_region'], df_rb_breweries['brewery_country_code'] = format_location(df_rb_breweries['brewery_location'])\n",
    "df_rb_breweries.drop(columns=['brewery_location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rb_breweries.to_csv('data/rate_beer/breweries.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rb_users = pd.read_csv('raw_data/rate_beer/users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rb_users = df_rb_users.groupby('user_id').agg({\n",
    "    'nbr_ratings': 'sum',\n",
    "    'user_name': 'first',\n",
    "    'joined': 'min',\n",
    "    'location': 'first',\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rb_users = df_rb_users.rename(columns={\n",
    "    'joined': 'user_created_date',\n",
    "    'location': 'user_location',\n",
    "    'nbr_ratings': 'user_ratings_count',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rb_users['user_country'], df_rb_users['user_region'], df_rb_users['user_country_code'] = format_location(df_rb_users['user_location'])\n",
    "df_rb_users = df_rb_users.drop(columns=['user_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rb_users.to_csv('data/rate_beer/users.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings & Reviews\n",
    "\n",
    "Since there are only ratings on RB, the files `ratings.txt` and `reviews.txt` are strictly identical. We discard `reviews.txt` and parse `ratings.txt` using the `txt_to_csv.cpp` utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\n",
    "    'src/scripts/txt_to_csv', \n",
    "    'raw_data/rate_beer/ratings.txt', \n",
    "    'raw_data/rate_beer/ratings.csv'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rb_ratings = pd.read_csv('raw_data/rate_beer/ratings.csv')\n",
    "df_rb_ratings = df_rb_ratings.groupby(['user_id', 'beer_id']).last().reset_index()\n",
    "df_rb_ratings = df_rb_ratings[['user_id', 'beer_id', 'brewery_id', 'date', 'rating', 'overall', 'aroma', 'appearance', 'palate', 'taste', 'text']]\n",
    "df_rb_ratings.to_csv('data/rate_beer/ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_rb_beers\n",
    "del df_rb_breweries\n",
    "del df_rb_users\n",
    "del df_rb_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matched Beer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ma_beers = pd.read_csv('raw_data/matched_beer_data/beers.csv', header=[0, 1])\n",
    "df_ma_beers = df_ma_beers[[('ba', 'beer_id'), ('rb', 'beer_id'), ('scores', 'diff'), ('scores', 'sim')]]\n",
    "df_ma_beers.to_csv('data/matched_beer_data/beers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breweries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ma_breweries = pd.read_csv('raw_data/matched_beer_data/breweries.csv', header=[0, 1])\n",
    "df_ma_breweries = df_ma_breweries.rename(columns={'id': 'brewery_id',}, level=1)\n",
    "df_ma_breweries = df_ma_breweries[[('ba', 'brewery_id'), ('rb', 'brewery_id'), ('scores', 'diff'), ('scores', 'sim')]]\n",
    "df_ma_breweries.to_csv('data/matched_beer_data/breweries.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ma_users = pd.read_csv('raw_data/matched_beer_data/users.csv', header=[0, 1])\n",
    "df_ma_users = df_ma_users[[('ba', 'user_id'), ('rb', 'user_id')]]\n",
    "df_ma_users.to_csv('data/matched_beer_data/users.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ma_users_approx = pd.read_csv('raw_data/matched_beer_data/users_approx.csv', header=[0, 1])\n",
    "df_ma_users_approx = df_ma_users_approx[[('ba', 'user_id'), ('rb', 'user_id'), ('scores', 'sim')]]\n",
    "df_ma_users_approx.to_csv('data/matched_beer_data/users_approx.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings & Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ma_ratings = pd.read_csv('raw_data/matched_beer_data/ratings.csv', header=[0, 1])\n",
    "df_ma_ratings = df_ma_ratings[[\n",
    "    ('ba', 'beer_id'), ('ba', 'user_id'), \n",
    "    ('rb', 'beer_id'), ('rb', 'user_id'),\n",
    "]]\n",
    "df_ma_ratings.to_csv('data/matched_beer_data/ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_ma_beers\n",
    "del df_ma_breweries\n",
    "del df_ma_users\n",
    "del df_ma_users_approx\n",
    "del df_ma_ratings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
