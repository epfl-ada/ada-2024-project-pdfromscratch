{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch import softmax\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_rating(df_predictions_batch: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_final_prediction_batch = pd.DataFrame()\n",
    "    for predicted_rating in range(1,6):\n",
    "        df_prediction_rating_batch = df_predictions_batch[df_predictions_batch.idxmax(axis=1).astype(int) == predicted_rating]\n",
    "        weight = df_prediction_rating_batch.iloc[:,predicted_rating-1]\n",
    "        rating = predicted_rating\n",
    "        if predicted_rating == 1:\n",
    "            weight_minus = 0\n",
    "            rating_minus = 0\n",
    "            weight_plus = df_prediction_rating_batch.iloc[:,predicted_rating]\n",
    "            rating_plus = 2\n",
    "        elif predicted_rating == 5:\n",
    "            weight_minus = df_prediction_rating_batch.iloc[:,predicted_rating-2]\n",
    "            rating_minus = 4\n",
    "            weight_plus = 0\n",
    "            rating_minus = 0\n",
    "        else:\n",
    "            weight_minus = df_prediction_rating_batch.iloc[:,predicted_rating-2]\n",
    "            rating_minus = predicted_rating-1\n",
    "            weight_plus = df_prediction_rating_batch.iloc[:,predicted_rating]\n",
    "            rating_plus = predicted_rating+1\n",
    "            \n",
    "        df_final_prediction_rating_batch = (weight_minus*rating_minus + weight*rating + weight_plus*rating_plus)/(weight_minus + weight + weight_plus)\n",
    "        df_final_prediction_rating_batch = pd.concat([df_final_prediction_rating_batch, weight_minus + weight + weight_plus],axis=1)\n",
    "        df_final_prediction_rating_batch.rename(columns={0:\"rating\",1:\"confidence\"},inplace=True)\n",
    "        df_final_prediction_batch = pd.concat([df_final_prediction_batch,df_final_prediction_rating_batch],axis=0)\n",
    "    return df_final_prediction_batch\n",
    "\n",
    "def predict_rating(reviews: pd.Series, tokenizer: AutoTokenizer, device: torch.device, model: AutoModelForSequenceClassification) -> pd.DataFrame:\n",
    "    encoded_input = tokenizer(reviews.tolist(), padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "    encoded_input = {key: tensor.to(device) for key, tensor in encoded_input.items()}\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "    scores = softmax(output.logits, dim=1)\n",
    "    return pd.DataFrame([\n",
    "        *scores.cpu().numpy()\n",
    "    ], columns=['1', '2', '3', '4', '5'], index=reviews.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv(\"../data/beer_advocate/ratings.csv\")\n",
    "\n",
    "HUGGING_FACE_MODEL = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(HUGGING_FACE_MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(HUGGING_FACE_MODEL)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "df_reviews = df_ratings[df_ratings['text'].str.len() > 377]['text']\n",
    "n_rows = len(df_reviews)\n",
    "\n",
    "df_final_predictions = pd.DataFrame()\n",
    "\n",
    "for start in tqdm(range(0, n_rows, BATCH_SIZE)):\n",
    "\n",
    "    end = min(start+BATCH_SIZE, n_rows)\n",
    "    batch = df_reviews.iloc[start:end]\n",
    "    df_predictions_batch = predict_rating(batch, tokenizer, device, model)\n",
    "    df_final_prediction_batch = compute_weighted_rating(df_predictions_batch)\n",
    "\n",
    "    df_final_predictions = pd.concat([df_final_predictions, df_final_prediction_batch], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beer Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "K_{L,u} = \\max\\limits_{\\mathcal{S}_i}(\\frac{|\\mathcal{S}_{i,u}|}{|\\mathcal{S}_i|})\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "K_{G,u} = \\frac{|\\mathcal{S}_u|}{|\\mathcal{S}|} \\cdot \\frac{\\log(1 + \\overline{|\\mathcal{S}_{i,u}|})}{\\log(1 + \\overline{|\\mathcal{S}_i|})}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "K_u = K_{G,u} \\cdot gini_u + K_{L,u} \\cdot (1 - gini_u)\n",
    "\\end{equation}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada_project_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
